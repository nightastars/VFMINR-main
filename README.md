# VFMINR-main
Sparse-view CT Reconstruction via Implicit Neural Representation Learning Powered by Dual-Domain Vision Foundation Models.

Note that FDVFM and SDVFM require re-pretraining based on your datasets.

If you want to train the network, run train.py and modify the parameter configurations; if you want to perform inference, run test.py and modify the parameter configurations.

Please pay attention to the dataset format. For specific format requirements, refer to data.py.

Paper Citation:
@article{wang2026sparse,
  title={Sparse-view CT Reconstruction via Implicit Neural Representation Learning Powered by Dual-Domain Vision Foundation Models},
  author={Wang, Jiping and Li, Ming and Fan, Hao and Chen, Yang and Yao, Yi and Liu, Yangchuan and Wu, Zhongyi and Du, Qiang and Yu, Hengyong and Zheng, Jian},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2026},
  publisher={IEEE}
}
